{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\n# from sklearn.metrics import classification_report, confusion_matrix\n\nimport nltk\n# import random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train0=pd.read_csv('/kaggle/input/math80600aw21/train.csv', header=None, names=['label', 'node_id'])\ntest0=pd.read_csv('/kaggle/input/math80600aw21/test.csv', header=None, names=['node_id']) \ntext=pd.read_csv('/kaggle/input/math80600aw21/text.csv', header=None, names=['paper_id','title','abstract'])\nnodeid2paperid=pd.read_csv('/kaggle/input/math80600aw21/nodeid2paperid.csv', header=0, names=['node_id','paper_id'])\n# sample=pd.read_csv('/content/gdrive/MyDrive/Kaggle/sample.csv', header=0, names= ['node_id','label'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Check the Missing Values","metadata":{}},{"cell_type":"code","source":"count_nan = len(train0) - train0.count()\ncount_nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**preparing the train and test data and saving them\n**","metadata":{}},{"cell_type":"markdown","source":"merging the train and test data with the text based on column 'node_id'  and frem left side","metadata":{}},{"cell_type":"code","source":"text= pd.merge(nodeid2paperid ,text,  how = 'left', on = 'paper_id')\ntext.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(train0 ,text,  how = 'left', on = 'node_id')\ntest = pd.merge(test0 ,text,  how = 'left', on = 'node_id')\nprint(train.columns)\nprint(test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setting the column order","metadata":{}},{"cell_type":"code","source":"train = train[['node_id', 'paper_id', 'title', 'abstract', 'label']]\ntest = test[['node_id', 'paper_id', 'title', 'abstract']]\nprint(train.shape)\nprint(test.shape)\nprint(text.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finding maximum length of sentence","metadata":{}},{"cell_type":"code","source":"print(train['label'].max())\nprint(text[\"title\"].map(len).max()) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Joining 'title' to 'abstract' as one column (named as 'abstract') to use them down the road\n","metadata":{}},{"cell_type":"code","source":"train['abstract'] = train[['title','abstract']].agg('-'.join, axis=1)\ntest['abstract'] = test[['title','abstract']].agg('-'.join, axis=1)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting the label records to see how imbalance the dataset is .\nHow awfully imbalnced data we have !","metadata":{}},{"cell_type":"code","source":"train['label'].value_counts().plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cleaning the text**","metadata":{}},{"cell_type":"code","source":"!pip install  unidecode\n!pip install word2number \n!pip install  contractions\n!pip install  bs4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport spacy\nimport unidecode\nfrom word2number import w2n\nimport contractions\n\nnlp = spacy.load('en')\n\n# exclude words from spacy stopwords list\ndeselect_stop_words = ['no', 'not']\nfor w in deselect_stop_words:\n    nlp.vocab[w].is_stop = False\n\n\ndef strip_html_tags(text):\n    \"\"\"remove html tags from text\"\"\"\n    soup = BeautifulSoup(text, \"html.parser\")\n    stripped_text = soup.get_text(separator=\" \")\n    return stripped_text\n\n\ndef remove_whitespace(text):\n    \"\"\"remove extra whitespaces from text\"\"\"\n    text = text.strip()\n    return \" \".join(text.split())\n\n\ndef remove_accented_chars(text):\n    \"\"\"remove accented characters from text, e.g. café\"\"\"\n    text = unidecode.unidecode(text)\n    return text\n\n\ndef expand_contractions(text):\n    \"\"\"expand shortened words, e.g. don't to do not\"\"\"\n    text = contractions.fix(text)\n    return text\n\n\ndef text_preprocessing(text, accented_chars=True, contractions=True, \n                       convert_num=True, extra_whitespace=True, \n                       lemmatization=True, lowercase=True, punctuations=True,\n                       remove_html=True, remove_num=True, special_chars=True, \n                       stop_words=True):\n    \"\"\"preprocess text with default option set to true for all steps\"\"\"\n    if remove_html == True: #remove html tags\n        text = strip_html_tags(text)\n    if extra_whitespace == True: #remove extra whitespaces\n        text = remove_whitespace(text)\n    if accented_chars == True: #remove accented characters\n        text = remove_accented_chars(text)\n    if contractions == True: #expand contractions\n        text = expand_contractions(text)\n    if lowercase == True: #convert all characters to lowercase\n        text = text.lower()\n\n    doc = nlp(text) #tokenise text\n\n    clean_text = []\n    \n    for token in doc:\n        flag = True\n        edit = token.text\n        # remove stop words\n        if stop_words == True and token.is_stop and token.pos_ != 'NUM': \n            flag = False\n        # remove punctuations\n        if punctuations == True and token.pos_ == 'PUNCT' and flag == True: \n            flag = False\n        # remove special characters\n        if special_chars == True and token.pos_ == 'SYM' and flag == True: \n            flag = False\n        # remove numbers\n        if remove_num == True and (token.pos_ == 'NUM' or token.text.isnumeric()) \\\n        and flag == True:\n            flag = False\n        # convert number words to numeric numbers\n        if convert_num == True and token.pos_ == 'NUM' and flag == True:\n            edit = w2n.word_to_num(token.text)\n        # convert tokens to base form\n        elif lemmatization == True and token.lemma_ != \"-PRON-\" and flag == True:\n            edit = token.lemma_\n        # append tokens edited and not removed to list \n        if edit != \"\" and flag == True:\n            clean_text.append(edit)        \n    return \" \".join(clean_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"removing also the mathematical symbols... ","metadata":{}},{"cell_type":"code","source":"import re\n\nregex = r\"(\\$+)(?:(?!\\1)[\\s\\S])*\\1\"\n\ntrain['abstract'] =  [re.sub(regex,'', str(x)) for x in train['abstract']]\ntest['abstract'] =  [re.sub(regex,'', str(x)) for x in test['abstract']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['abstract']=train['abstract'].apply(text_preprocessing)\ntest['abstract']=test['abstract'].apply(text_preprocessing)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"dropping the title since we joined it to 'abstract' column","metadata":{}},{"cell_type":"code","source":"train = train.drop('title', axis=1)\ntest = test.drop('title', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Saving the cleaned train and test","metadata":{}},{"cell_type":"code","source":"train_clean = pd.DataFrame({'node_id':train.node_id,'paper_id':train.paper_id,'abstract':train.abstract,'label':train.label},columns=['node_id','paper_id','abstract', 'label'])\ntrain_clean.to_csv('/kaggle/input/math80600aw21/train_clean.csv', index=False,header=True)\ntrain_clean.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_clean = pd.DataFrame({'node_id':test.node_id,'paper_id':test.paper_id,'abstract':test.abstract},columns=['node_id','paper_id','abstract'])\ntest_clean.to_csv('/kaggle/input/math80600aw21/test_clean.csv', index=False,header=True)\ntest_clean.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Read prepared tain and test**","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/math80600aw21/train_clean.csv')\ntrain.head()\n\ntest=pd.read_csv('/kaggle/input/math80600aw21/test_clean.csv')\ntest.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Text Classification using BiLSTM**","metadata":{}},{"cell_type":"markdown","source":"Trying oversampling and Undersampling ( they did not help me )","metadata":{}},{"cell_type":"code","source":"# from imblearn.under_sampling import RandomUnderSampler\n# y_train = train['label']\n# x_train= train.drop('label', axis=1)\n# # define undersample strategy\n# undersample = RandomUnderSampler() \n# # fit and apply the transform\n# X_under, Y_under = undersample.fit_resample(x_train, y_train)\n\n# df1 = pd.DataFrame(X_under,columns=['abstract'])\n# df2 = pd.DataFrame(Y_under,columns=['label'])\n# df = df1.join(df2)\n# # df = pd.DataFrame(df,columns=['abstract','label'])\n# # df=df.groupby('label').apply(lambda x: x.sample(1000))\n# print(df.shape)\n# df['label'].value_counts().plot(kind='bar')\n# X_under=df.drop('label', axis=1)\n# Y_under =df['label']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = train.drop(train[train['label'] == 16].sample(frac=0.7).index)\n# train = train.drop(train[train['label'] == 10].sample(frac=0.3).index)\n# train = train.drop(train[train['label'] == 8].sample(frac=0.2).index)\n# train = train.drop(train[train['label'] == 4].sample(frac=0.2).index)\n# train = train.drop(train[train['label'] == 5].sample(frac=0.1).index)\n# train = train.drop(train[train['label'] == 2].sample(frac=0.1).index)\n\n\n# train['label'].value_counts()\n# train['label'].value_counts().plot(kind='bar')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys, os, re, csv, codecs, numpy as np, pandas as pd\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers \nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n\nfrom tensorflow import keras\nfrom keras.models import Sequential","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"See the important words in each category ","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords# nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nn_posts = 5000\nw_0 = ' '.join(train[train['label'] == 0]['abstract'].str.lower().values[:n_posts])\nw_1 = ' '.join(train[train['label'] == 1]['abstract'].str.lower().values[:n_posts])\nw_2 = ' '.join(train[train['label'] == 2]['abstract'].str.lower().values[:n_posts])\nw_3 = ' '.join(train[train['label'] == 3]['abstract'].str.lower().values[:n_posts])\n\n\nwordcloud_0 = WordCloud(max_font_size=None, stopwords=stop,scale = 2,colormap = 'Dark2').generate(w_0)\nwordcloud_1 = WordCloud(max_font_size=None, stopwords=stop,scale = 2,colormap = 'Dark2').generate(w_1)\nwordcloud_2 = WordCloud(max_font_size=None, stopwords=stop,scale = 2,colormap = 'Dark2').generate(w_2)\nwordcloud_3 = WordCloud(max_font_size=None, stopwords=stop,scale = 2,colormap = 'Dark2').generate(w_3)\n\nfig, ax = plt.subplots(1,4, figsize=(20, 5))\nax[0].imshow(wordcloud_0)\nax[0].set_title('Top words in label 1',fontsize = 20)\nax[0].axis(\"off\")\n\nax[1].imshow(wordcloud_1)\nax[1].set_title('Top words in label 2',fontsize = 20)\nax[1].axis(\"off\")\n\nax[2].imshow(wordcloud_2)\nax[2].set_title('Top words in label 1',fontsize = 20)\nax[2].axis(\"off\")\n\nax[3].imshow(wordcloud_3)\nax[3].set_title('Top words in label 2',fontsize = 20)\nax[3].axis(\"off\")\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys, os, re, csv, codecs, numpy as np, pandas as pd\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reading glove embedding and trying different dimensions : 50,100,200 ","metadata":{}},{"cell_type":"code","source":"EMBEDDING_FILE= '../input/glove6b50dtxt/glove.6B.200d.txt'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed_size = 200 # length of each word vector\nmax_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\nmaxlen = 100 # max number of words in a abstract","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tokenizing the senetences ","metadata":{}},{"cell_type":"code","source":"list_sentences_train = train['abstract'].values\nlist_sentences_test = test['abstract'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read the glove word vectors (space delimited strings) into a dictionary from word->vector.","metadata":{}},{"cell_type":"code","source":"def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nemb_mean,emb_std","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))+1\nembedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp = Input(shape=(maxlen,))\ninp.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"defining the model","metadata":{}},{"cell_type":"code","source":"inp = Input(shape=(maxlen,))\n\nx = Embedding(20001, embed_size, weights=[embedding_matrix],trainable=False)(inp)\nx = Bidirectional(LSTM(512, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(400, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(200, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(100, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(50, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(20, activation=\"softmax\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"using early stopping to avoid overfitting. also saving the best model in terms of accuracy on valid set","metadata":{}},{"cell_type":"code","source":"# model = getModel()\nmodel.summary()\n\n\nearlyStopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=0, mode='max')\nmcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy',mode='max',)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"trying to give weights to classes ( did not help me much) ","metadata":{}},{"cell_type":"code","source":"# from sklearn.utils import class_weight\n# class_weights = class_weight.compute_class_weight('balanced', np.unique(y),y)\n# class_weights\n\n# weight_dict={}\n# for i in range(len(class_weights)):\n#   weight_dict[i] = class_weights[i]\n# weight_dict\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"categorzing the target variable to use it in the model/ ","metadata":{}},{"cell_type":"code","source":"y = train['label'].values\nnp.unique(y)\nfrom keras.utils import to_categorical\ny = to_categorical(y, 20)\ny","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_t, y, batch_size=1024, epochs=100, verbose=1, callbacks=[earlyStopping, mcp_save] , validation_split=0.1)  #class_weight=weight_dict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save('/content/gdrive/MyDrive/Kaggle')\n# from tensorflow import keras\n# model = keras.models.load_model('/content/gdrive/MyDrive/Kaggle')\n#!nvidia-smi","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"f1 metric since we are doing multi class classification and we have an imbalanced dataset to see the performance in each class as well","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\ny_pred = model.predict([X_t], batch_size=1024, verbose=1)\ny_pred=np.argmax(y_pred,axis=1)\ny_true=train['label']\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_true, y_pred, labels=[0,1, 2, 3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = model.predict([X_te], batch_size=1024, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = pd.DataFrame({'id':test.node_id,'label':pred},columns=['id', 'label'])\npredict.to_csv('/kaggle/input/math80600aw21/predict1.csv', index=False,header=True)\npredict.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have tested different \n-activation functions : tanh , elu , relu, leakyrelu, ... \n-number of neurons for diferent BiLSTM and dense layers : from 32-512 and  from 20-400  respectivly\n-Batch sizes : from 8-4096 and\n-Learning rates : 1e-1 to 1e-5\n-also used dropout and BatchNormalisation. \n-I have also tried ubdersampling,oversampling and giving weights to the classes to address data imbalance. \nand ... \n\nI could not get better resulst than 79% accuarcy with BiLSTM","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Using the Bert model**","metadata":{}},{"cell_type":"markdown","source":"Matching the versions in differnt packages","metadata":{}},{"cell_type":"code","source":"!pip install 'torch== 1.4.0'\n!pip install 'pandas== 1.0.3'\n!pip install 'numpy ==1.18.2'\n!pip install 'transformers==2.8.0'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/math80600aw21/train_clean.csv')\ntrain","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nimport torch\nfrom torch.nn import functional as F\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import defaultdict\nfrom textwrap import wrap\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"using the \"cased\" version of Bert since my text is not like a tweet, so nobody writes BAD in an academic text instead of bad. o there is no semantic difference in capital letters or Not-capital letters.  ","metadata":{}},{"cell_type":"code","source":"PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"loading a pre-trained BertTokenizer:","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Choosing Sequence Length BERT works with fixed-length sequences. We’ll use a simple strategy to choose the max length. Let’s store the token length of each review:","metadata":{}},{"cell_type":"code","source":"df=train.copy()\n\ntoken_lens = []\nfor txt in df.abstract:\n  tokens = tokenizer.encode(txt, max_length=512)\n  token_lens.append(len(tokens))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the reviews seem to contain less than 250 tokens, but we’ll be on the safe side and choose a maximum length of 250.","metadata":{}},{"cell_type":"code","source":"sns.distplot(token_lens)\nplt.xlim([0, 512]);\nplt.xlabel('Token count');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 250","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GPReviewDataset(Dataset):\n  def __init__(self, reviews, targets, tokenizer, max_len):\n    self.reviews = reviews\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n  def __len__(self):\n    return len(self.reviews)\n  def __getitem__(self, item):\n    review = str(self.reviews[item])\n    target = self.targets[item]\n    encoding = self.tokenizer.encode_plus(\n      review,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n    return {\n      'review_text': review,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(target, dtype=torch.long)\n    }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\ndf_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\ndf_train.shape, df_val.shape, df_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len, batch_size):\n  ds = GPReviewDataset(\n    reviews=df.abstract.to_numpy(),\n    targets=df.label.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len\n  )\n  return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4\n  )\nBATCH_SIZE = 15\ntrain_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = next(iter(train_data_loader))\ndata.keys()\n\n\nprint(data['input_ids'].shape)\nprint(data['attention_mask'].shape)\nprint(data['targets'].shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check our training data loader:","metadata":{}},{"cell_type":"code","source":"data = next(iter(train_data_loader))\ndata.keys()\n\n\nprint(data['input_ids'].shape)\nprint(data['attention_mask'].shape)\nprint(data['targets'].shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_hidden_state, pooled_output = bert_model(input_ids=encoding['input_ids'], attention_mask=encoding['attention_mask'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"768  is the number of hidden units in the feedforward-networks. We can verify that by checking the config:","metadata":{}},{"cell_type":"code","source":"bert_model.config.hidden_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentimentClassifier(nn.Module):\n\n  def __init__(self, n_classes):\n    super(SentimentClassifier, self).__init__()\n    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n    self.drop = nn.Dropout(p=0.5)\n    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n    \n\n  def forward(self, input_ids, attention_mask):\n    _, pooled_output = self.bert(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n    output = self.drop(pooled_output)\n    return self.out(output)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.memory_summary(device=None, abbreviated=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentimentClassifier(len(df['label']))\nmodel = model.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = data['input_ids'].to(device)\nattention_mask = data['attention_mask'].to(device)\n\nprint(input_ids.shape) # batch size x seq length\nprint(attention_mask.shape) # batch size x seq length","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"F.softmax(model(input_ids, attention_mask), dim=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention_mask","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 5\n\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=True)\ntotal_steps = len(train_data_loader) * EPOCHS\n\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\n\nloss_fn = nn.CrossEntropyLoss().to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(\n  model, \n  data_loader, \n  loss_fn, \n  optimizer, \n  device, \n  scheduler, \n  n_examples\n):\n  model = model.train()\n\n  losses = []\n  correct_predictions = 0\n  \n  for d in data_loader:\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n\n    _, preds = torch.max(outputs, dim=1)\n    loss = loss_fn(outputs, targets)\n\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n\n    loss.backward()\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n  model = model.eval()\n\n  losses = []\n  correct_predictions = 0\n\n  with torch.no_grad():\n    for d in data_loader:\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n\n      loss = loss_fn(outputs, targets)\n\n      correct_predictions += torch.sum(preds == targets)\n      losses.append(loss.item())\n\n  return correct_predictions.double() / n_examples, np.mean(losses)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nhistory = defaultdict(list)\nbest_accuracy = 0\n\nfor epoch in range(EPOCHS):\n\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\n  print('-' * 10)\n\n  train_acc, train_loss = train_epoch(\n    model,\n    train_data_loader,    \n    loss_fn, \n    optimizer, \n    device, \n    scheduler, \n    len(df_train)\n  )\n\n  print(f'Train loss {train_loss} accuracy {train_acc}')\n\n  val_acc, val_loss = eval_model(\n    model,\n    val_data_loader,\n    loss_fn, \n    device, \n    len(df_val)\n  )\n\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\n  print()\n\n  history['train_acc'].append(train_acc)\n  history['train_loss'].append(train_loss)\n  history['val_acc'].append(val_acc)\n  history['val_loss'].append(val_loss)\n\n  if val_acc > best_accuracy:\n    torch.save(model.state_dict(), 'best_model_state.bin')\n    best_accuracy = val_acc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history['train_acc'], label='train accuracy')\nplt.plot(history['val_acc'], label='validation accuracy')\n\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.ylim([0, 1]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_acc, _ = eval_model(\n  model,\n  test_data_loader,\n  loss_fn,\n  device,\n  len(df_test)\n)\n\ntest_acc.item()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(model, data_loader):\n  model = model.eval()\n  \n  review_texts = []\n  predictions = []\n  prediction_probs = []\n  real_values = []\n\n  with torch.no_grad():\n    for d in data_loader:\n\n      texts = d[\"review_text\"]\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n      _, preds = torch.max(outputs, dim=1)\n\n      probs = F.softmax(outputs, dim=1)\n\n      review_texts.extend(texts)\n      predictions.extend(preds)\n      prediction_probs.extend(probs)\n      real_values.extend(targets)\n\n  predictions = torch.stack(predictions).cpu()\n  prediction_probs = torch.stack(prediction_probs).cpu()\n  real_values = torch.stack(real_values).cpu()\n  return review_texts, predictions, prediction_probs, real_values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n  model,\n  test_data_loader\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred)) #, target_names=class_names","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, '/content/gdrive/MyDrive/Kaggle/slow_model_1.pt')\n# slow_model = torch.load('/content/gdrive/MyDrive/Kaggle/slow_model.pt')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['label']=None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(test)):\n \n  encoded_review = tokenizer.encode_plus(test['abstract'][i], \n                                         max_length=MAX_LEN,\n                                         add_special_tokens=True, \n                                         return_token_type_ids=False,  \n                                         pad_to_max_length=True,  \n                                         return_attention_mask=True,  \n                                         return_tensors='pt',)\n  \n  input_ids = encoded_review['input_ids'].to(device)\n  attention_mask = encoded_review['attention_mask'].to(device)\n  \n  output = model(input_ids, attention_mask)\n  _, prediction = torch.max(output, dim=1)\n  test['label'][i]=prediction.item()\n  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_bert = pd.DataFrame({'node_id':test.node_id,'paper_id':test.paper_id,'abstract':test.abstract,'label':test.label},columns=['node_id','paper_id','abstract','label'])\n\nprediction_bert = prediction_bert.drop('paper_id', axis=1)\nprediction_bert = prediction_bert.drop('abstract', axis=1)\n\nprediction_bert = pd.DataFrame({'id':prediction_bert.node_id,'label':prediction_bert.label},columns=['id', 'label'])\nprediction_bert.to_csv('/content/gdrive/MyDrive/Kaggle/prediction_bert_1.csv', index=False, header=True)\nprediction_bert.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Using two (Pre-trained and Not Pre-Trained Bert( different from the previous OFF-THE_SHELF Bert model that I have used from HuggingFace Tutorials) models and averaging their results as final prediction**","metadata":{}},{"cell_type":"markdown","source":"I have used differnt number of layers and hyperparamters besied using some other pre-trained models like Roberta but Bert has yielded better results for me. ","metadata":{}},{"cell_type":"markdown","source":"**Using pretrained and not-pretrained BERT (ensemble)**","metadata":{}},{"cell_type":"markdown","source":"Checking the Colab ","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In cacse, If they are not installed ","metadata":{}},{"cell_type":"code","source":"# !pip install Spacy\n! pip install transformers > null\n! pip install tokenizers > null","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.nn import functional as F\nimport pandas as pd\nimport gc\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\ntorch.cuda.empty_cache()\nimport numpy as np\nimport gc\ngc.collect()\nimport pandas as pd\nimport transformers\nfrom transformers import AutoModel,AutoConfig\nimport plotly\nimport numpy as np\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom sklearn.cluster import KMeans\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset, DataLoader\nimport scipy\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import classification_report, accuracy_score,f1_score\nimport time\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\nbatch_size = 32\nmax_len = 250\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/content/drive/MyDrive/Kaggle/train_clean.csv\")\nprint(len(train_data))\n# valid_data = pd.read_csv(\"/content/drive/MyDrive/Kaggle/test_clean.csv\")\nvalid_data = train_data.sample(frac=0.1)\ntrain_data = train_data.drop(index=valid_data.index)\nprint(len(train_data))\nprint(len(valid_data))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"double check","metadata":{}},{"cell_type":"code","source":"train_data[\"abstract\"] = train_data[\"abstract\"].astype(str)\nvalid_data[\"abstract\"] = valid_data[\"abstract\"].astype(str)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df,tokenizer,max_len=32):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        df = self.df.iloc[idx]\n        if isinstance(idx, int):\n            abstract = [df['abstract']]\n            label = [df['label']]\n            \n        else:\n            abstract = df['abstract'].to_list()\n            label = df['label'].to_list()\n            \n        abstract_t = self.tokenizer(abstract, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=self.max_len)\n        label_t = torch.LongTensor(label)\n        \n        return {'input_ids':abstract_t['input_ids'].squeeze().to(device),\n                \"attention_mask\":abstract_t['attention_mask'].squeeze().to(device),\n                \"token_type_ids\":abstract_t['token_type_ids'].squeeze().to(device),\n                \"label\":label_t.squeeze().to(device),\n               \n                   }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import AutoModelForSequenceClassification\n# model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', return_dict=True)\n# model.to(device)\n\n# from transformers import AutoTokenizer\n# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n\n# from transformers import AdamW\n# # optimizer = AdamW(model.parameters(), lr=1e-5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"calling both Pre-trained and NOt-pretrained Bert","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n# model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', return_dict=True)\n# model.to(device)\n\nfrom transformers import AutoConfig\nconfig = AutoConfig.from_pretrained('bert-base-uncased')\nmodel =  AutoModelForSequenceClassification.from_config(config)\nmodel.to(device)\n\n\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n\nfrom transformers import AdamW\n# optimizer = AdamW(model.parameters(), lr=1e-5)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = MyDataset(train_data, tokenizer, max_len=250)\nvalid_dataset = MyDataset(valid_data, tokenizer, max_len=250)\ntrain_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I could have also used 1024 hidden units for Bert but I used  768 to be easier since my computational power was low.","metadata":{}},{"cell_type":"code","source":"from torch.autograd import Function\nclass MainModule(nn.Module):\n    def __init__(self, bert):\n        super(MainModule, self).__init__()\n        self.bert = bert\n        self.dropout = nn.Dropout(0.25)\n        self.cls_out = nn.Linear(768, 20)\n        \n    def forward(self,batch_data):\n        shared_output = self.bert(batch_data['input_ids'], batch_data['attention_mask'], batch_data['token_type_ids'])  \n        ###################################      \n        pooled_output = shared_output[1]\n        ###################################\n        pooled_output_dropped = self.dropout(pooled_output)\n        logits_out = self.cls_out(pooled_output_dropped)\n        return_dict = {\"logits_out\":logits_out}\n        return return_dict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torch.autograd import Function\n# class MainModule(nn.Module):\n#     def __init__(self, bert):\n#         super(MainModule, self).__init__()\n#         self.bert = bert\n#         self.dropout = nn.Dropout(0.5)\n#         self.classifier = nn.Sequential(\n#             nn.Linear(768, 500),\n#             nn.ReLU(),\n#             nn.Dropout(0.5),\n#             nn.Linear(500, 20),\n#             nn.Dropout(0.5)\n#         )\n\n#     def forward(self,batch_data):\n#         shared_output = self.bert(batch_data['input_ids'], batch_data['attention_mask'], batch_data['token_type_ids'])  \n#         ###################################      \n#         pooled_output = shared_output[1]\n#         ###################################\n#         pooled_output_dropped = self.dropout(pooled_output)\n#         logits_out = self.classifier(pooled_output_dropped)\n#         return_dict = {\"logits_out\":logits_out}\n#         return return_dict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MainModule(model.bert)\nmodel.to(device)\noptimizer = AdamW(model.parameters(), lr=1e-5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors=['blue','green','cyan', 'black', 'red','yellow','brown']\ndef plot_cm(labels, preds):\n    cm = confusion_matrix(labels, preds)\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(cm)\n    fig.colorbar(cax)\n    for i in range(len(cm)):\n        for j in range(len(cm)):\n            plt.annotate(cm[i,j],xy=(j,i),horizontalalignment='center',verticalalignment='center',size=15,color='orange') \n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def report(logits, labels):\n    logits = np.concatenate(logits, axis=0)\n    logits = np.argmax(logits, axis=-1)\n    labels = np.concatenate(labels, axis=0)\n    print(classification_report(labels, logits))\n    plot_cm(labels, logits)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_evaluation(model, data_loader):\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    model.eval()\n    with torch.no_grad():\n        labels = []\n        logits = []\n        \n        for batch, batch_data in enumerate(data_loader):\n            # optimizer.zero_grad()\n            outputs = model(batch_data)\n            labels.append(batch_data['label'].cpu().detach().numpy())\n            logits.append(outputs['logits_out'].cpu().detach().numpy())\n        # loss /= (batch + 1)\n        report(logits, labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()\n\nmodel.train()\nepochs = 1\nfor epoch in range(1,epochs+1):\n    labels_out_list = []\n    logits_out_list = []\n    \n    for batch, batch_data in enumerate(train_data_loader):\n        optimizer.zero_grad()\n        outputs = model(batch_data)\n        loss = F.cross_entropy(outputs['logits_out'], batch_data['label'])\n        \n        loss.backward()\n        optimizer.step()\n\n        labels_out_list.append(batch_data['label'])\n        logits_out_list.append(outputs['logits_out'])\n       \n\n\n        log_interval = 25\n        if batch % log_interval == 0:\n            print(\" epoch=\",epoch,\"  batch=\",batch,\"   loss=\",loss.item())\n    print('------------------------------------')\n    labels_out_list = [i.cpu().detach().numpy() for i in labels_out_list]\n    logits_out_list = [i.cpu().detach().numpy() for i in logits_out_list]\n    report(logits_out_list, labels_out_list)\n    print('************************')\n    model_evaluation(model, valid_data_loader)\n    # torch.save(model, \"/content/drive/MyDrive/Kaggle/models/\" + str(epoch) +\".pt\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=pd.read_csv('/content/drive/MyDrive/Kaggle/test_clean.csv')\ntest","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['label']=None\n# test = test.drop('paper_id', axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDatasetTest(Dataset):\n    def __init__(self, df,tokenizer,max_len=32):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        df = self.df.iloc[idx]\n        if isinstance(idx, int):\n            abstract = [df['abstract']]\n            \n        else:\n            abstract = df['abstract'].to_list()\n            \n        abstract_t = self.tokenizer(abstract, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=self.max_len)\n        \n        return {'input_ids':abstract_t['input_ids'].squeeze().to(device),\n                \"attention_mask\":abstract_t['attention_mask'].squeeze().to(device),\n                \"token_type_ids\":abstract_t['token_type_ids'].squeeze().to(device),\n                }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = MyDatasetTest(test, tokenizer, max_len=250)\n\n\ntest_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_prediction(model, data_loader):\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    model.eval()\n    with torch.no_grad():\n        \n        logits = []\n        \n        for batch, batch_data in enumerate(data_loader):\n            \n            outputs = model(batch_data)\n            \n            logits.append(outputs['logits_out'].cpu().detach().numpy())\n        \n    return logits","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I saved the models to be able to use them again ","metadata":{}},{"cell_type":"code","source":"# torch.save(model.state_dict(), '/content/drive/MyDrive/Kaggle/model_bert_not_trained.pt')\ntorch.save(model, \"/content/drive/MyDrive/Kaggle/Model_whole_bert_not_trained.pt\")\n# Model class must be defined somewhere\n# model = torch.load(\"/content/drive/MyDrive/Kaggle/Model_whole_bert.pt\")\n# model.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_pretrained = torch.load(\"/content/drive/MyDrive/Kaggle/Model_whole_bert.pt\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_bert_pretrained=model_prediction(model_pretrained,test_data_loader)\nlabels_bert_pretrained","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits_pretrained = np.concatenate(labels_bert_pretrained, axis=0)\nlogits_pretrained.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"using Softmax to get pred probs","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nlabels_bert_pretrained_prob = []\nfor i in tqdm(logits_pretrained):\n  sum = np.sum(np.exp(i))\n  labels_bert_pretrained_prob.append(np.exp(i)/sum)\nlabels_bert_pretrained_prob","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_not_trained = torch.load(\"/content/drive/MyDrive/Kaggle/Model_whole_bert_not_trained.pt\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_bert_not_pretrained=model_prediction(model_not_trained,test_data_loader)\nlabels_bert_not_pretrained","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits_not_pretrained = np.concatenate(labels_bert_not_pretrained, axis=0)\nlogits_not_pretrained.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"using Softmax to get pred probs","metadata":{}},{"cell_type":"code","source":"labels_bert_not_pretrained_prob = []\nfor i in tqdm(logits_not_pretrained):\n  sum = np.sum(np.exp(i))\n  labels_bert_not_pretrained_prob.append(np.exp(i)/sum)\nlabels_bert_not_pretrained_prob","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Averaging the results","metadata":{}},{"cell_type":"code","source":"labels = []\nfor i in range(len(labels_bert_not_pretrained_prob)):\n  labels.append((labels_bert_not_pretrained_prob[i] + labels_bert_pretrained_prob[i])/2)\n# labels = (labels_bert_not_pretrained_prob + labels_bert_pretrained_prob) / 2\nlabels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_csv('/content/drive/MyDrive/Kaggle/submit.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# logits = np.concatenate(labels, axis=0)\nlogits = np.argmax(labels, axis=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['label']=logits\ntest","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_Java = pd.DataFrame({'id':test.node_id,'label':test.label},columns=['id','label'])\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_Java.to_csv('/content/drive/MyDrive/Kaggle/prediction_Java.csv', index=False, header=True)\nprediction_Java.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_Java","metadata":{},"execution_count":null,"outputs":[]}]}